{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtbqheZVAjTF"
      },
      "outputs": [],
      "source": [
        "# first extract the file in input.csv  file only extract the"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first extract the file in input.csv  file only extract the title and heaser"
      ],
      "metadata": {
        "id": "xVHRocA4AzlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dascCAdcCc0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def validate_url(url):\n",
        "    regex = r\"https?://.*\"\n",
        "    if re.match(regex, url):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Validate the URLs in the data frame\n",
        "df['URL'] = df['URL'].apply(validate_url)\n",
        "\n",
        "# Remove any rows with invalid URLs\n",
        "df = df[df['URL'].notna()]"
      ],
      "metadata": {
        "id": "B9RycUNRFRxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Tm1yBcwFSxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGNHBkfLFVvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "gAI2p3NsBiwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "IXwLW4c_BjOO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMWeKcKiA5Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yanl2BXzD8th",
        "outputId": "9f9565a5-31ce-42fb-bd7e-b656afd1ff0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*"
      ],
      "metadata": {
        "id": "2Y168NyiAyoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure the required NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to extract article title and body\n",
        "def extract_article_content(url):\n",
        "    if not url:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract title (this might vary depending on the website's HTML structure)\n",
        "        title_tag = soup.find('h1')\n",
        "        title = title_tag.get_text(strip=True) if title_tag else 'No Title'\n",
        "\n",
        "        # Extract article text (this might vary depending on the website's HTML structure)\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = '\\n'.join([para.get_text(strip=True) for para in paragraphs])\n",
        "\n",
        "        return title, article_text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to retrieve article from {url}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to perform textual analysis\n",
        "def analyze_text(title, article_text):\n",
        "    words = word_tokenize(article_text)\n",
        "    sentences = sent_tokenize(article_text)\n",
        "\n",
        "    word_count = len(words)\n",
        "    character_count = len(article_text)\n",
        "    average_word_length = sum(len(word) for word in words) / word_count if word_count else 0\n",
        "    sentence_count = len(sentences)\n",
        "    average_sentence_length = word_count / sentence_count if sentence_count else 0\n",
        "\n",
        "    return {\n",
        "        'Title': title,\n",
        "        'Article Text': article_text,\n",
        "        'Word Count': word_count,\n",
        "        'Character Count': character_count,\n",
        "        'Average Word Length': average_word_length,\n",
        "        'Number of Sentences': sentence_count,\n",
        "        'Average Sentence Length': average_sentence_length\n",
        "    }\n",
        "\n",
        "# Load data from the Excel file\n",
        "input_file_path = '/Input (1).xlsx'\n",
        "df = pd.read_excel(input_file_path)\n",
        "\n",
        "# Directory to save the articles\n",
        "output_dir = 'articles'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# DataFrame to store results\n",
        "results = []\n",
        "\n",
        "# Iterate through the dataframe and save articles\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    title, article_text = extract_article_content(url)\n",
        "    if title and article_text:\n",
        "        # Save article text to a file named after the URL_ID\n",
        "        file_name = f\"{url_id}.txt\"\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "\n",
        "        # Perform textual analysis\n",
        "        analysis = analyze_text(title, article_text)\n",
        "        analysis['URL_ID'] = url_id\n",
        "        results.append(analysis)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve article from {url}\")\n",
        "\n",
        "# Create a DataFrame from results\n",
        "output_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_file_path = '/Data Structure.xlsx'\n",
        "output_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(\"Textual analysis completed and results saved to Output Data Structure.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TewRgofEXvU",
        "outputId": "abc2b499-9224-4fb8-dbac-8fb58b0d56d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Textual analysis completed and results saved to Output Data Structure.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gZB7c3sNMDaI",
        "outputId": "88cf9273-85c5-42af-f2be-7d89a48d365b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Title  \\\n",
              "0   Rising IT cities and its impact on the economy...   \n",
              "1   Rising IT Cities and Their Impact on the Econo...   \n",
              "2   Internet Demand’s Evolution, Communication Imp...   \n",
              "3   Rise of Cybercrime and its Effect in upcoming ...   \n",
              "4   OTT platform and its impact on the entertainme...   \n",
              "..                                                ...   \n",
              "93  Due to the COVID-19 the repercussion of the en...   \n",
              "94  Impact of COVID-19 pandemic on office space an...   \n",
              "95  Contribution of handicrafts (Visual Arts & Lit...   \n",
              "96     How COVID-19 is impacting payment preferences?   \n",
              "97        How will COVID-19 affect the world of work?   \n",
              "\n",
              "                                         Article Text  Word Count  \\\n",
              "0   Efficient Supply Chain Assessment: Overcoming ...         605   \n",
              "1   Efficient Supply Chain Assessment: Overcoming ...        1822   \n",
              "2   Efficient Supply Chain Assessment: Overcoming ...        1439   \n",
              "3   Efficient Supply Chain Assessment: Overcoming ...        1435   \n",
              "4   Efficient Supply Chain Assessment: Overcoming ...         985   \n",
              "..                                                ...         ...   \n",
              "93  Efficient Supply Chain Assessment: Overcoming ...        1436   \n",
              "94  Efficient Supply Chain Assessment: Overcoming ...        1427   \n",
              "95  Efficient Supply Chain Assessment: Overcoming ...         394   \n",
              "96  Efficient Supply Chain Assessment: Overcoming ...         832   \n",
              "97  Efficient Supply Chain Assessment: Overcoming ...        1263   \n",
              "\n",
              "    Character Count  Average Word Length  Number of Sentences  \\\n",
              "0              3398             4.738843                   29   \n",
              "1             10733             5.029638                   80   \n",
              "2              9166             5.502432                   61   \n",
              "3              8923             5.358188                   56   \n",
              "4              5981             5.193909                   43   \n",
              "..              ...                  ...                  ...   \n",
              "93             8556             5.050836                   54   \n",
              "94             7690             4.505256                   42   \n",
              "95             2381             5.205584                    9   \n",
              "96             4629             4.689904                   32   \n",
              "97             7289             4.893112                   34   \n",
              "\n",
              "    Average Sentence Length           URL_ID  \n",
              "0                 20.862069  blackassign0001  \n",
              "1                 22.775000  blackassign0002  \n",
              "2                 23.590164  blackassign0003  \n",
              "3                 25.625000  blackassign0004  \n",
              "4                 22.906977  blackassign0005  \n",
              "..                      ...              ...  \n",
              "93                26.592593  blackassign0096  \n",
              "94                33.976190  blackassign0097  \n",
              "95                43.777778  blackassign0098  \n",
              "96                26.000000  blackassign0099  \n",
              "97                37.147059  blackassign0100  \n",
              "\n",
              "[98 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce534565-4b39-4c5a-8888-4624d037c080\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Article Text</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Character Count</th>\n",
              "      <th>Average Word Length</th>\n",
              "      <th>Number of Sentences</th>\n",
              "      <th>Average Sentence Length</th>\n",
              "      <th>URL_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rising IT cities and its impact on the economy...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>605</td>\n",
              "      <td>3398</td>\n",
              "      <td>4.738843</td>\n",
              "      <td>29</td>\n",
              "      <td>20.862069</td>\n",
              "      <td>blackassign0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rising IT Cities and Their Impact on the Econo...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1822</td>\n",
              "      <td>10733</td>\n",
              "      <td>5.029638</td>\n",
              "      <td>80</td>\n",
              "      <td>22.775000</td>\n",
              "      <td>blackassign0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Internet Demand’s Evolution, Communication Imp...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1439</td>\n",
              "      <td>9166</td>\n",
              "      <td>5.502432</td>\n",
              "      <td>61</td>\n",
              "      <td>23.590164</td>\n",
              "      <td>blackassign0003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rise of Cybercrime and its Effect in upcoming ...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1435</td>\n",
              "      <td>8923</td>\n",
              "      <td>5.358188</td>\n",
              "      <td>56</td>\n",
              "      <td>25.625000</td>\n",
              "      <td>blackassign0004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OTT platform and its impact on the entertainme...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>985</td>\n",
              "      <td>5981</td>\n",
              "      <td>5.193909</td>\n",
              "      <td>43</td>\n",
              "      <td>22.906977</td>\n",
              "      <td>blackassign0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Due to the COVID-19 the repercussion of the en...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1436</td>\n",
              "      <td>8556</td>\n",
              "      <td>5.050836</td>\n",
              "      <td>54</td>\n",
              "      <td>26.592593</td>\n",
              "      <td>blackassign0096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Impact of COVID-19 pandemic on office space an...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1427</td>\n",
              "      <td>7690</td>\n",
              "      <td>4.505256</td>\n",
              "      <td>42</td>\n",
              "      <td>33.976190</td>\n",
              "      <td>blackassign0097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Contribution of handicrafts (Visual Arts &amp; Lit...</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>394</td>\n",
              "      <td>2381</td>\n",
              "      <td>5.205584</td>\n",
              "      <td>9</td>\n",
              "      <td>43.777778</td>\n",
              "      <td>blackassign0098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>How COVID-19 is impacting payment preferences?</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>832</td>\n",
              "      <td>4629</td>\n",
              "      <td>4.689904</td>\n",
              "      <td>32</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>blackassign0099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>How will COVID-19 affect the world of work?</td>\n",
              "      <td>Efficient Supply Chain Assessment: Overcoming ...</td>\n",
              "      <td>1263</td>\n",
              "      <td>7289</td>\n",
              "      <td>4.893112</td>\n",
              "      <td>34</td>\n",
              "      <td>37.147059</td>\n",
              "      <td>blackassign0100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce534565-4b39-4c5a-8888-4624d037c080')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce534565-4b39-4c5a-8888-4624d037c080 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce534565-4b39-4c5a-8888-4624d037c080');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d42b5b16-d596-4f39-b562-de0e304c54c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d42b5b16-d596-4f39-b562-de0e304c54c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d42b5b16-d596-4f39-b562-de0e304c54c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2c5b16f6-a4a0-413e-8323-0cfd81b63316\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('output_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2c5b16f6-a4a0-413e-8323-0cfd81b63316 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('output_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "output_df",
              "summary": "{\n  \"name\": \"output_df\",\n  \"rows\": 98,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"Evolution of Advertising Industry\",\n          \"An outlook of healthcare by the year 2040, and how it will impact human lives.\",\n          \"Will technology eliminate the need for animal testing in drug development?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Article Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"Efficient Supply Chain Assessment: Overcoming Technical Hurdles for Web Application Development\\nStreamlined Integration: Interactive Brokers API with Python for Desktop Trading Application\\nEfficient Data Integration and User-Friendly Interface Development: Navigating Challenges in Web Application Deployment\\nEffective Management of Social Media Data Extraction: Strategies for Authentication, Security, and Reliability\\nAI Bot Audio to audio\\nMethodology for ETL Discovery Tool using LLMA, OpenAI, Langchain\\nMethodology for database discovery tool using openai, LLMA, Langchain\\nChatbot using VoiceFlow\\nRising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\\nRising IT Cities and Their Impact on the Economy, Environment, Infrastructure, and City Life in Future\\nInternet Demand\\u2019s Evolution, Communication Impact, and 2035\\u2019s Alternative Pathways\\nRise of Cybercrime and its Effect in upcoming Future\\nAI/ML and Predictive Modeling\\nSolution for Contact Centre Problems\\nHow to Setup Custom Domain for Google App Engine Application?\\nCode Review Checklist\\nWe\\u2019ve really done it this year. Like an insatiable glutton, the law of averages has come home to roost. We should\\u2019ve taken the hint when on the 1stof January, 66 people lost their lives in the Jakarta floods. What followed was like the highlights reel of a disaster movie franchise \\u2013 a volcanic eruption in The Philippines, irrepressible bushfires in Australia, earthquakes in Russia, Iran, Turkey, India, and China. And speaking of China.\\n2020 has brought home the fragile mortality of the human race into sharp focus. As global Covid-19 deaths stoutly push past the grim 1 million marks, we have no choice but to question our place in the universe \\u2013 are we the all-conquering masters of our domain, or mere tourists in a ruthlessly apathetic ecosystem? Is the human race on the ubiquitous three-part literary arc that defines every story, every life, every civilization \\u2013 ascent, apex, and descent? Maybe when Michael Jackson unveiled his moonwalk in 1983, or when Barack Obama stepped into the White House as President of the United States in 2008, or indeed when MS Dhoni lifted the Cricket World Cup in 2011, we peaked, as a species, and everything since then has been a steady unraveling.\\n500 years is a long time. For context, the world population in 1500 AD was a mere 461 million. The 16-fold explosion since then is unprecedented in history, but we might just be at the tip of an iceberg. Though fertility rates are dropping and more and more people are foregoing the chance to have babies, we might just have crossed the threshold \\u2013 the population projections for the year 2050 is 9.8 billion, and for 2100 is a whopping 11.2 billion1. Somewhere out there, Malthus is cackling in his grave. The year 2500 suddenly seems a long way off, and this conversation seems ever-more pertinent today. The Bulletin of Atomic Scientists is not optimistic \\u2013 the famed Doomsday Clock they maintain is the closest to \\u2018midnight\\u2019 (our proximity to global catastrophe), since its inception in 1947. Global warming? Check. The threat of nuclear war? Check. Ongoing pandemic? Check, check, check.\\nAnd yet, hope floats, for three reasons. Mankind may just have its back to the wall right now, but there are three shoots of potential that might just help us make it to 2500 AD \\u2013 the advent of a basket of disruptive technologies (artificial intelligence, bio-enhancement, genetic engineering), the private sector focus on space exploration and terraforming, and good old fashioned human resilience. While the first two factors will no doubt be critical to human survival, it is the third one that we must pin our hopes on \\u2013 our long-demonstrated history of surviving whatever nature, the universe, or our own self-destructive tendency, throws our way.\\nThe Next Superman?\\nIn the 13thcentury, in the Italian town of Pisa, an enterprising tinkerer developed the first eyeglasses, for a local friar with weakening eyesight2. All of a sudden, there existed an external device that could amplify our senses, a tool that gave us an advantage in survival. Today, LASIK surgeries obviate the need for eyeglasses entirely. Hearing aids give the gift of auditory perception back to those who had gotten used to a world of muffled voices and unheard sounds. The iPhone routinely comes with an augmented reality tool that allows us to measure the length of objects in front of us.\\nBut the real science starts where the imagination ends \\u2013 augmented reality glasses, smart wearables, and virtual reality tools will be ubiquitous in the next few decades. But what after that? Science has the answer, and it\\u2019s both thrilling and scary. Artificial intelligence has become the stuff of fable, the filler for all questions left unanswered. But AI, combined with bio-enhancement and genetic engineering, might just lead to the evolution of what some are calling Homonouveau3. Homonouveauwill be smarter, faster, more agile, and better equipped to adapt to what promises to be a world that is VUCA beyond our imaginations. What might such a human being look like?\\nThey might have a small chip embedded in their brain that utilizes artificial intelligence for enhanced sensory perception. What does that mean? It means that they would be able to see better, focuses their attention for longer, hears what they want to hear, and communicate the appropriate reaction to the rest of the body. Through a chemical in the blood, this AI chip would be able to demand the appropriate response from the body. Bio-augmentation of limbs and organs, internal and external, would mean that what a person can or cannot do is no longer determined at birth, but can simply be bought. All of a sudden, the average Joe can run faster than Usain Bolt, swim better than Michael Phelps, and\\u2026fly? Maybe. Genetic engineering will be the missing link. Already there are feverish conversations about a dystopian future featuring designer babies and a digital divide that simply cannot be overcome because it is inbuilt into one\\u2019s DNA. The breakthrough with CRISPR-Cas9 might just be the key to unlock the mysteries of DNA manipulation. So what if there\\u2019s no food left? Our body AI will adjust our appetite accordingly. No water? Absorb humidity from the air through specialized pores in the skin. The human being in 2500 AD may not be how we recognize one today. That may be our only shot.\\nGalactic Dominance\\nSpaceX, led by its mercurial leader Elon Musk, has been the leader here. The SpaceX Mars Programme is based on a very simple premise \\u2013 as the earth\\u2019s closest planet in terms of distance and terrestrial conditions, Mars would be our best bet for colonization. Musk has invested billions of dollars in the Mars Space Programme and remains a fervent believer in the concept. And among tech visionaries, Musk is not alone. Jeff Bezos, the richest man in the world, owns Blue Origin, which simply aims to make spaceflight cheaper through incremental technological growth. Bezos, who took an online retailer of books and turned it into an ever-expanding behemoth, is not a man who thinks small. With more and more business leaders finding spaceflight and planetary colonization a tantalizing prospect, there will inevitably be a concerted push to developing an actual colony on another planet. And when the pull-factor to this development starts hitting diminishing returns, there will be the inevitable push factor as global warming and the possible increase in the eruption of pandemics begin to take their toll. It might just become a more feasible option for people to find an alternate home, if not on Mars, then on one of Saturn\\u2019s moons.\\nA human colony on Mars sounds like a concept straight out of science fiction, but so did a permanent station in Antarctica until a few decades ago. Mount Everest seemed like an unapproachable summit until someone went ahead and planted a flag at the peak. Today, hundreds of people every year attempt the climb. As spaceflight becomes more reasonable, as the urge to explore supersedes the inertia of investment, we become closer to our best chance of survival \\u2013 leaving planet earth behind and finding another home, perhaps one more forgiving of our follies.\\nThe Human Spirit\\nThe introduction to this article includes an illustrative list of disasters and misfortunes that have struck the global communitythis year. And yet, we survive. Businesses surge ahead, people adapt to a world of masks and social distancing, the world goes on. Earthquakes, tsunamis, pandemics, we\\u2019ve seen them all before and survived, and the human race, in its intrepid exploration of the world, pushes onward and upward. Technological visionaries envision a future that the rest of us cannot see, and then invest money in their vision. Gradually, what seemed unthinkable suddenly becomes real \\u2013 the moon landing is the best possible example of that. Google launched Google Glass as the first augmented reality wearable technology, and suddenly we could foresee a future with smart eyewear. While the product didn\\u2019t quite catch on, that doesn\\u2019t mean other companies aren\\u2019t trying. Bio-augmentation is already a fast-developing industry, while CRISPR-Cas9, the \\u201cgenetic scissors\\u201d is being held back only by regulatory bottlenecks. How long before the prospect of fiddling with the gene code becomes not a luxury but a necessity? The human spirit, the tendency to survive and thrive at all costs, will eventually win.\\nThe human race will survive to 2500, of that there is no doubt. The real question is, will the person who exists in 2500, with bionic chips and a bio-enhanced body structure and a modified genetic code, be called a Homosapien?Or is Homonouveauthe way forward?\\n\\nWe provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\\nContact us:hello@blackcoffer.com\\n\\u00a9 All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\",\n          \"Efficient Supply Chain Assessment: Overcoming Technical Hurdles for Web Application Development\\nStreamlined Integration: Interactive Brokers API with Python for Desktop Trading Application\\nEfficient Data Integration and User-Friendly Interface Development: Navigating Challenges in Web Application Deployment\\nEffective Management of Social Media Data Extraction: Strategies for Authentication, Security, and Reliability\\nAI Bot Audio to audio\\nMethodology for ETL Discovery Tool using LLMA, OpenAI, Langchain\\nMethodology for database discovery tool using openai, LLMA, Langchain\\nChatbot using VoiceFlow\\nRising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\\nRising IT Cities and Their Impact on the Economy, Environment, Infrastructure, and City Life in Future\\nInternet Demand\\u2019s Evolution, Communication Impact, and 2035\\u2019s Alternative Pathways\\nRise of Cybercrime and its Effect in upcoming Future\\nAI/ML and Predictive Modeling\\nSolution for Contact Centre Problems\\nHow to Setup Custom Domain for Google App Engine Application?\\nCode Review Checklist\\nArtificial intelligence and employment are the burning issues nowadays workers need clarity on as we head into the longer term. This article focuses on the various impact of AI on our jobs and explains the benefits of AI in our workplace. That right there must have hit a nerve. However, everything is about to change because this article highlights some of the reasons we should not fear AI.\\nAI is the abbreviation of Artificial Intelligence. Artificial intelligence is often defined as a set of various technologies which will be brought together to permit machines to act with what appears to be human-like levels of intelligence. This includes learning rules required to make certain decisions and reasoning to arrive at certain conclusions, learning from past experiences, and self-correction.\\nAI is of two types.\\n1940\\nExpectations that machines could match humans in terms of general intelligence. By that, we mean machines could have the capability to find out, Reason, and React.\\n1950\\nAlan Turing develops the Turing Test; a test to determine whether a machine is intelligent.However, it wasn\\u2019t for another 60 years or so that any program was deemed to have passed.\\n1955\\nThe first time a computer virus defeats a person\\u2019s World Champion during a parlor game.\\n1956\\nJohn McCarthy invents the new term \\u2018Artificial Intelligence\\u2019 when he held the primary Academic Conference on the subject of AI.\\n1962\\nArthur Samuel\\u2018s machine learning checkers (draughts) program, beat a checkers master.\\n1980\\nReinforcement Learning is introduced. This is a kind of programming that uses rewards and punishments to coach a machine to interact with its environment.\\n2012\\nA research group led by Geoffrey Hinton wins the Image Net competition \\u2013 this competition requires AI to categorize about 1.2 million images into any of 10,000 different categories. The level of accuracy was adequate to that of the typical human completing an equivalent task manually.\\n2014\\nEugene Goostman\\u2019s chatbot, a bot pretending to be a 13-year-old boy, supposedly passes the Turing Test, a test which nobody has passed before! But controversy arose with this claim as:\\n1. Experts claim it only lasted five minutes.\\n2. It had been deemed biased as Eugene\\u2019s mother tongue (Ukrainian) wasn\\u2019t equivalent to the judge\\u2019s (English), which is a plus as language is one among the few ways we will tell the difference between a person\\u2019s and machine.\\n2018\\nAlibaba\\u2019s AI Model performs better than humans during a reading and comprehension test at Stanford University, scoring 82.44 against the 82.304 scored by humans!\\nArtificial Intelligence (AI) is here to remain, and lots of people aren\\u2019t happy. After all, it\\u2019s hard to embrace something that would displace about 40 percent of human jobs within the next 15 years. In an interview for CBS\\u2019s hour, Kai-Fu Lee (a Chinese AI expert) also mentioned truck drivers, chauffeurs, waiters, and chefs as a number of the professions that will be disrupted.\\nBut if you were to ask the experts, they might unwaveringly confirm that no matter all the noise, AI is here to profit us all. Case in point, an executive briefing by the McKinsey Global Institute revealed that AI and automation are creating opportunities for the economy, society, and business.\\nThat said, it\\u2019s time to repress the widespread idea of artificial intelligence taking jobs. So, let\\u2019s highlight a number of the useful developments you\\u2019ll expect from this technological phenomenon.\\nWhile the relationship between artificial intelligence and jobs is a matter of hot debate, it is still safe to say that AI will indeed offer new opportunities. According to the planet Economic Forum report, robots and AI will create as many AI jobs as they displace. This conclusion is entirely viable as it is easy to identify some of the many careers in artificial intelligence, for example, data scientists, who evaluate the decisions made by AI algorithms to eliminate any biases. Apart from that, some other AI occupations include:\\nTransparency analysts: people tasked with classifying the varied sorts of opacity for algorithms. Smart-system interaction modelers: experts who develop machine behavior based on employee behavior. Machine-relations managers: people that champion the greater use of algorithms that perform well. As far because the competition for jobs between humans and robots goes, worth noting is that there are jobs that AI can\\u2019t replace. Roles that need leadership, empathy, and delegation are samples of the various jobs that are safe from automation.\\nAutomation will stir positive change in the workplace. When AI is employed during recruitment or maybe performance management, all workers are going to be evaluated in an unbiased, fact-based manner. In turn, Human Resources managers can get to consider other essential strategic undertakings that ensure balance within the workplace.\\nAI can help HR departments to use machine learning (ML) in discovering where issues like bias stem from and assist them to act accordingly faster. ML shines in identifying instances of bias. In turn, this may promote fairness and variety within the work setting.\\nThe impact of AI in business is already felt, and this is often expected to continue through to the longer term. A few years from now, AI-oriented architecture is forecasted to require the lead in assisting businesses to hold out operations in additional comprehensive ways, thus shifting them from traditional data science and machine learning models. It will be necessary to maneuver to business outcomes because AI will play an important role in multiple aspects of the business. While there is no way of telling the future of artificial intelligence in business for sure, it makes sense for owners to keep up with the evolution to avoid being left behind.\\nThe workforce of the longer term will lean more towards innovation and creativity. Businesses have spent higher a part of the previous couple of years studying AI automation and the way they will leverage it to realize results fast. With statistics showing that workers spend up to 40 percent of their hours at work performing repetitive tasks, every business should consider automating any functions which will be automated. Automation is not new; machines have been replacing human labor in different areas for decades.\\nHowever, within the coming years, mundane daily tasks will become fully automated. Already, 39 percent of organizations were completely reliant on automation in 2018. With repetitive tasks taken care of, employees can focus their energies on high-value customer-oriented tasks and collaboration. The designs of workplaces and workflows will also change with the implementation of AI technology. More people will begin to figure more closely with machines as companies will strive to become more agile.\\nCompanies that implement AI in their business strategy will experience dramatic improvements in their customer experiences, and their employees are going to be more motivated. Encouraging creativity rather than the performance of repetitive tasks gives workers more fulfillment in their jobs as well.\\nWith the web of things and AI working hand in hand, identifying trends and solving problems within the business world will become more convenient and also sustainable. AI, alongside other technologies, is predicted to vary the planet by impacting the way businesses run. With time, we\\u2019ll be ready to combine both human and artificial brains to seek out solutions to major global problems.\\nIt will even be easier to foresee problems with more accuracy and nip them at the bud with the help of AI. But these positive impacts can only be felt if stakeholders are transparent and mindful in their use of the technology for the greater good of everyone else.\\nAccording to a report by PWC, 54 percent of companies confirm that the implementation of AI-driven solutions in their companies has already improved productivity. AI and automation, even once they are implemented partially, have unlimited potential for any business. Workers\\u2019 skills, attitude, training, command chain, and workflows protocols are a number of the leading productivity challenges that companies face.\\nApart from increasing productivity, AI systems will help businesses to chop down on costs, improve the standard of their products or services, and make better customer profiles. As a result, companies also will get higher profits, which may be shared among stakeholders as dividends, or reinvest it back within the business. Improved productivity also means firms are going to be ready to sell their products at lower prices, thereby creating more demand among customers and more job opportunities for workers. Businesses can, therefore, use human labor to take up those jobs that have been created by AI and cannot be automated.\\nArtificial Intelligence isn\\u2019t showing any signs of slowing down. Soon, it\\u2019ll become another necessity of life, a bit like the web. But for now, more and more businesses are beginning to realize how invaluable AI automation and data interpretation are. Though machines will take some jobs initially, the roles created by automation will also keep soaring within the next few years.\\nWill, we\\u2019ve reached the purpose of accelerating human intelligence by artificial means? Who knows? What we all know, however, is that those that are going to be sought-after in AI and employment are individuals who have the relevant skills. There\\u2019s work that not even the machines can do; so, we should make ourselves as valuable as we can be in our field and we will be irreplaceable.\\n\\nWe provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\\nContact us:hello@blackcoffer.com\\n\\u00a9 All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\",\n          \"Efficient Supply Chain Assessment: Overcoming Technical Hurdles for Web Application Development\\nStreamlined Integration: Interactive Brokers API with Python for Desktop Trading Application\\nEfficient Data Integration and User-Friendly Interface Development: Navigating Challenges in Web Application Deployment\\nEffective Management of Social Media Data Extraction: Strategies for Authentication, Security, and Reliability\\nAI Bot Audio to audio\\nMethodology for ETL Discovery Tool using LLMA, OpenAI, Langchain\\nMethodology for database discovery tool using openai, LLMA, Langchain\\nChatbot using VoiceFlow\\nRising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\\nRising IT Cities and Their Impact on the Economy, Environment, Infrastructure, and City Life in Future\\nInternet Demand\\u2019s Evolution, Communication Impact, and 2035\\u2019s Alternative Pathways\\nRise of Cybercrime and its Effect in upcoming Future\\nAI/ML and Predictive Modeling\\nSolution for Contact Centre Problems\\nHow to Setup Custom Domain for Google App Engine Application?\\nCode Review Checklist\\nCOVID 19 has bought the world to its knees. With businesses being shut, travel being banned, schools, and colleges being closed, we have observed an impeccable amount of sorrow and despise along with a great amount of mental torture and destruction. Though situations are improving now, and the lockdowns are being lifted, it is a fact that it cannot be shunned that this virus will have a long term impact on people, and the effects will not only be felt economically and physically but also mentally.\\nWe\\u2019ve been reading articles regarding the impact of COVID 19 on the economy, education, mental health, and every other possible aspect. But one topic which has not been talked about much is the impact of COVID 19 on office space and co-working industries. Well, it is quite obvious that offices will start functioning now, but, the COVID period hasn\\u2019t ended. This means that social distancing will also have to be followed in offices; where it will be a problem to do so because of the lack of adequate infrastructure and space. The same will be the condition in co-working industries, wherein employees of different companies come and work together under the same roof.\\nHowever, these problems are quite obvious (though people haven\\u2019t thought about them much), but the fact which people fail to notice and understand is that the meaning of space is not only limited to infrastructural space which is measured in square foot or square meters; but it also extends to metal space, or for that fact, space in the minds of people for others and their thoughts as well as opinions.\\nCoronavirus has left a big scratch in our country; just the way a car needs repair after an accident, our country will also need repair after the control of this virus. But, unlike a car, our country will require a large amount of time to get restored and to stand straight without any support.\\nNeedless to say, the economic stability of our country will definitely be hit because of this reason. But the problem is since the earnings of the employers will reduce, it will subsequently lead to a drop in the salary of the employees. While some employees might be preferred by their bosses and may receive a raise regularly, others might be subjected to unfair treatment and made to do the same amount of work for a lower salary.\\nPeople tend to overlook the thin line which exists between cooperation and competition. The problem doesn\\u2019t arise when such a situation happens wherein an employee is getting paid more than the other, but instead, it arises when people start to compare their earnings as well as benefits to that of others. And in today\\u2019s world, where people keep money at the top of their priority list, comparisons will play a very important role in the performance of employees and their company.\\nSince there will exist inequalities and partialities in companies, there will also exist a sense of hatred and competition among the employees of the same company; who will compete to get a better position or a raise in their salary. This may seem beneficial to some as it might compel the employees to work harder and better, but however, will bring huge losses in the long run. The fact is; employees might end up doing unethical acts which will help them to make a better impression in their boss\\u2019s eyes.\\nMoreover, since there will be comparisons among the employees, it might happen that the \\u2018Employee of the Month\\u2019 ends up being hated by all other employees in the company. Another situation that might arise is that of bluffing and pretending; wherein employees tend to show that they work very hard but they don\\u2019t. This might be practiced by showing the boss that they are working when he is on around, and then chilling the rest of the time when the boss goes home or sits in his office. In fact, employees might also lose interest in working if they sense repeated partialities and inequalities; which they might show by quitting the jobs or not performing to their best.\\nSuch situations will definitely arise in companies and offices; wherein employees will compete for attention and resources; which will have a great impact on the company and its functioning. And all this will happen because of only one thing; lack of office mental space i.e. space in the minds of people working together in a particular office for cooperation and teamwork, along with ignorance of the fact that things will get better and eventually the same after some time.\\nAnother kind of industry and companies that will be affected due to the long-lasting impact of COVID 19 is the co-working industry and offices. This is because, there will be a shortage of resources and the income of people, but the maintenance cost to be born for the infrastructure, as well the rent will remain the same. Because of this, employees will be told by the company owners to exploit the resources present in the offices and use them to the fullest; to compensate for the losses being born and to make better use of the money being used. However, the number of resources will be the same, and so, there will be a case of competition between employees of different companies to use resources and take benefits of the same.\\nIf the above two situations happen to occur at the same time (which they most likely will), we will observe a scene of intra-company as well as inter-company competition. Also, our personal relations with other employees in the company might also be affected due to this comparison and competition; which itself will be a result of limited mental space.\\nCOVID 19 will have severe impacts on the office (mental) space of companies and people.\\u00a0 People\\u2019s thoughts, how they treat others, along with accepting defeat and rejection will be an important aspect of everyone\\u2019s lives. Moreover, we might also observe a shoot in the intensity and frequency of office people going to psychologists; because of repeated rejection and unfair treatment. However, we need to cope with this thing and realize that it is indeed very important for us to start preparing to expand our mental space and that this competition and comparison will not stay for long and should not affect our personal relations and life at any cost.\\nWe provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\\nContact us:hello@blackcoffer.com\\n\\u00a9 All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 621,\n        \"min\": 389,\n        \"max\": 4197,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          2243,\n          1877,\n          1034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Character Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3434,\n        \"min\": 2288,\n        \"max\": 22228,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          10138,\n          11070,\n          7690\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Word Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28542091888204457,\n        \"min\": 4.280806979280261,\n        \"max\": 5.594936708860759,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          4.515119363395225,\n          4.709319899244332,\n          4.505255781359495\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of Sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 9,\n        \"max\": 199,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          29,\n          85,\n          114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Sentence Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.773921128702424,\n        \"min\": 17.02469135802469,\n        \"max\": 161.30769230769232,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          18.088709677419356,\n          29.328125,\n          35.6551724137931\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"blackassign0065\",\n          \"blackassign0042\",\n          \"blackassign0097\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import syllapy\n",
        "\n",
        "\n",
        "\n",
        "# Load positive and negative words\n",
        "# Assuming we have lists of positive and negative words\n",
        "positive_words = set()\n",
        "negative_words = set()\n",
        "with open('positive-words.txt') as f:\n",
        "    positive_words = set(f.read().split())\n",
        "with open('negative-words.txt') as f:\n",
        "    negative_words = set(f.read().split())\n",
        "\n",
        "# Function to extract article title and body\n",
        "def extract_article_content(url):\n",
        "    if not url:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract title (this might vary depending on the website's HTML structure)\n",
        "        title_tag = soup.find('h1')\n",
        "        title = title_tag.get_text(strip=True) if title_tag else 'No Title'\n",
        "\n",
        "        # Extract article text (this might vary depending on the website's HTML structure)\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = '\\n'.join([para.get_text(strip=True) for para in paragraphs])\n",
        "\n",
        "        return title, article_text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to retrieve article from {url}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to perform textual analysis\n",
        "def analyze_text(title, article_text):\n",
        "    words = word_tokenize(article_text)\n",
        "    sentences = sent_tokenize(article_text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    word_count = len(words)\n",
        "    character_count = sum(len(word) for word in words)\n",
        "    average_word_length = character_count / word_count if word_count else 0\n",
        "    sentence_count = len(sentences)\n",
        "    average_sentence_length = word_count / sentence_count if sentence_count else 0\n",
        "\n",
        "    positive_score = sum(1 for word in words if word in positive_words)\n",
        "    negative_score = sum(1 for word in words if word in negative_words)\n",
        "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
        "    subjectivity_score = (positive_score + negative_score) / (word_count + 0.000001)\n",
        "\n",
        "    complex_words = [word for word in words if syllapy.count(word) >= 3]\n",
        "    complex_word_count = len(complex_words)\n",
        "    percentage_of_complex_words = complex_word_count / word_count if word_count else 0\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_of_complex_words)\n",
        "\n",
        "    syllables_per_word = sum(syllapy.count(word) for word in words) / word_count if word_count else 0\n",
        "\n",
        "    personal_pronouns = sum(1 for word in words if word in ['i', 'we', 'my', 'ours', 'us', 'me', 'mine', 'our'])\n",
        "\n",
        "    return {\n",
        "        'Title': title,\n",
        "        'Article Text': article_text,\n",
        "        'Word Count': word_count,\n",
        "        'Character Count': character_count,\n",
        "        'Average Word Length': average_word_length,\n",
        "        'Number of Sentences': sentence_count,\n",
        "        'Average Sentence Length': average_sentence_length,\n",
        "        'Positive Score': positive_score,\n",
        "        'Negative Score': negative_score,\n",
        "        'Polarity Score': polarity_score,\n",
        "        'Subjectivity Score': subjectivity_score,\n",
        "        'Percentage of Complex Words': percentage_of_complex_words,\n",
        "        'Fog Index': fog_index,\n",
        "        'Complex Word Count': complex_word_count,\n",
        "        'Syllables Per Word': syllables_per_word,\n",
        "        'Personal Pronouns': personal_pronouns\n",
        "    }\n",
        "# Load data from the Excel file\n",
        "input_file_path = '/Input (1).xlsx'\n",
        "df = pd.read_excel(input_file_path)\n",
        "\n",
        "# Directory to save the articles\n",
        "output_dir = 'articles'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# DataFrame to store results\n",
        "results = []\n",
        "\n",
        "# Iterate through the dataframe and save articles\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    title, article_text = extract_article_content(url)\n",
        "    if title and article_text:\n",
        "        # Save article text to a file named after the URL_ID\n",
        "        file_name = f\"{url_id}.txt\"\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "\n",
        "        # Perform textual analysis\n",
        "        analysis = analyze_text(title, article_text)\n",
        "        analysis['URL_ID'] = url_id\n",
        "        results.append(analysis)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve article from {url}\")\n",
        "\n",
        "# Create a DataFrame from results\n",
        "output_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_file_path = '/content/Output Data Structure.xlsx'\n",
        "output_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(\"Textual analysis completed and results saved to Output Data Structure.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "DpYEit1XMlde",
        "outputId": "81e1cf34-4b26-4348-ab57-eae38e2aa48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-68edba802284>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'URL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_article_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marticle_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Save article text to a file named after the URL_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-68edba802284>\u001b[0m in \u001b[0;36mextract_article_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Extract title (this might vary depending on the website's HTML structure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#print(\"START\", name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourcepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         tag = self.soup.handle_starttag(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msourcepos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         tag = self.element_classes.get(Tag, Tag)(\n\u001b[0m\u001b[1;32m    750\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentTag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_list_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m                 attrs = builder._replace_cdata_list_attribute_values(\n\u001b[0m\u001b[1;32m   1263\u001b[0m                     self.name, attrs)\n\u001b[1;32m   1264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py\u001b[0m in \u001b[0;36m_replace_cdata_list_attribute_values\u001b[0;34m(self, tag_name, attrs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             tag_specific = self.cdata_list_attributes.get(\n\u001b[1;32m    313\u001b[0m                 tag_name.lower(), None)\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniversal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag_specific\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0;31m# We have a \"class\"-type attribute whose string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install syllapy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrUooO7SULl2",
        "outputId": "2bd67059-51f1-4601-e91c-a1dcd1cc93b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting syllapy\n",
            "  Downloading syllapy-0.7.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: syllapy\n",
            "Successfully installed syllapy-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import pyphen\n",
        "\n",
        "# Ensure the required NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load positive and negative words\n",
        "positive_words = set()\n",
        "negative_words = set()\n",
        "with open('positive-words.txt') as f:\n",
        "    positive_words = set(f.read().split())\n",
        "with open('negative-words.txt') as f:\n",
        "    negative_words = set(f.read().split())\n",
        "\n",
        "# Pyphen dictionary for syllable counting\n",
        "dic = pyphen.Pyphen(lang='en')\n",
        "\n",
        "# Function to count syllables in a word\n",
        "def count_syllables(word):\n",
        "    return len(dic.inserted(word).split('-'))\n",
        "\n",
        "# Function to extract article title and body\n",
        "def extract_article_content(url):\n",
        "    if not url:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract title (this might vary depending on the website's HTML structure)\n",
        "        title_tag = soup.find('h1')\n",
        "        title = title_tag.get_text(strip=True) if title_tag else 'No Title'\n",
        "\n",
        "        # Extract article text (this might vary depending on the website's HTML structure)\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = '\\n'.join([para.get_text(strip=True) for para in paragraphs])\n",
        "\n",
        "        return title, article_text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to retrieve article from {url}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to perform textual analysis\n",
        "def analyze_text(title, article_text):\n",
        "    words = word_tokenize(article_text)\n",
        "    sentences = sent_tokenize(article_text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    word_count = len(words)\n",
        "    character_count = sum(len(word) for word in words)\n",
        "    average_word_length = character_count / word_count if word_count else 0\n",
        "    sentence_count = len(sentences)\n",
        "    average_sentence_length = word_count / sentence_count if sentence_count else 0\n",
        "\n",
        "    positive_score = sum(1 for word in words if word in positive_words)\n",
        "    negative_score = sum(1 for word in words if word in negative_words)\n",
        "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
        "    subjectivity_score = (positive_score + negative_score) / (word_count + 0.000001)\n",
        "\n",
        "    complex_words = [word for word in words if count_syllables(word) >= 3]\n",
        "    complex_word_count = len(complex_words)\n",
        "    percentage_of_complex_words = complex_word_count / word_count if word_count else 0\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_of_complex_words)\n",
        "\n",
        "    syllables_per_word = sum(count_syllables(word) for word in words) / word_count if word_count else 0\n",
        "\n",
        "    personal_pronouns = sum(1 for word in words if word in ['i', 'we', 'my', 'ours', 'us', 'me', 'mine', 'our'])\n",
        "\n",
        "    return {\n",
        "        'Title': title,\n",
        "        'Article Text': article_text,\n",
        "        'Positive Score': positive_score,\n",
        "        'Negative Score': negative_score,\n",
        "        'Polarity Score': polarity_score,\n",
        "        'Subjectivity Score': subjectivity_score,\n",
        "        'Average Sentence Length': average_sentence_length,\n",
        "        'Percentage of Complex Words': percentage_of_complex_words,\n",
        "        'Fog Index': fog_index,\n",
        "        'Average Number of Words Per Sentence': average_sentence_length,  # same as average sentence length\n",
        "        'Complex Word Count': complex_word_count,\n",
        "        'Word Count': word_count,\n",
        "        'Syllables Per Word': syllables_per_word,\n",
        "        'Personal Pronouns': personal_pronouns,\n",
        "        'Average Word Length': average_word_length\n",
        "    }\n",
        "\n",
        "# Load data from the Excel file\n",
        "input_file_path = '/content/Input (1).xlsx'\n",
        "df = pd.read_excel(input_file_path)\n",
        "\n",
        "# Directory to save the articles\n",
        "output_dir = 'articles'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# DataFrame to store results\n",
        "results = []\n",
        "\n",
        "# Iterate through the dataframe and save articles\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    title, article_text = extract_article_content(url)\n",
        "    if title and article_text:\n",
        "        # Save article text to a file named after the URL_ID\n",
        "        file_name = f\"{url_id}.txt\"\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "\n",
        "        # Perform textual analysis\n",
        "        analysis = analyze_text(title, article_text)\n",
        "        analysis['URL_ID'] = url_id\n",
        "        for col in df.columns:\n",
        "            analysis[col] = row[col]\n",
        "        results.append(analysis)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve article from {url}\")\n",
        "\n",
        "# Create a DataFrame from results\n",
        "output_df = pd.DataFrame(results)\n",
        "\n",
        "# Define the output file path\n",
        "output_file_path = '/content/Output Data Structure.xlsx'\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(\"Textual analysis completed and results saved to Output Data Structure.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsBZR8lRQDZL",
        "outputId": "77b04ddb-481e-429a-8f07-8f84fff48b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Failed to retrieve article from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Textual analysis completed and results saved to Output Data Structure.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLuCAT26SjjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}